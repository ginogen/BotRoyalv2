"""
üïí Follow-up Scheduler para Royal Bot v2
Sistema de programaci√≥n inteligente de follow-ups
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
import pytz
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.executors.asyncio import AsyncIOExecutor
from apscheduler.triggers.interval import IntervalTrigger
import psycopg2
from psycopg2.extras import RealDictCursor

logger = logging.getLogger('followup.scheduler')

class FollowUpScheduler:
    """Scheduler principal para follow-ups autom√°ticos"""
    
    def __init__(self, database_url: str, timezone: str = "America/Argentina/Cordoba",
                 evolution_api_url: str = None, evolution_token: str = None, 
                 instance_name: str = None, openai_api_key: str = None):
        self.database_url = database_url
        self.timezone = pytz.timezone(timezone)
        self.scheduler = None
        self.is_running = False
        
        # Configuraci√≥n Evolution API para el manager
        self.evolution_api_url = evolution_api_url
        self.evolution_token = evolution_token
        self.instance_name = instance_name
        self.openai_api_key = openai_api_key
        
        # Configuraci√≥n de etapas (en horas)
        self.stage_delays = {
            1: 0.25,   # 15 minutos
            2: 1,      # 1 hora
            3: 24,     # 1 d√≠a
            4: 48,     # 2 d√≠as
            5: 72,     # 3 d√≠as
            6: 96,     # 4 d√≠as
            7: 120     # 5 d√≠as
        }
        
        # üö® MODO MIGRACI√ìN: Protecci√≥n anti-duplicaci√≥n temporal
        self.migration_mode_until = None
        self._check_migration_mode()
        
        # Horarios permitidos
        self.start_hour = 9   # 9 AM
        self.end_hour = 21    # 9 PM
        self.allowed_weekdays = [1, 2, 3, 4, 5, 6]  # Lunes a s√°bado
    
    def _ensure_argentina_timezone(self, dt_input) -> datetime:
        """
        üö® VERSI√ìN CR√çTICA: Helper ultra-robusto para timezone Argentina con m√∫ltiples fallbacks
        VITAL para follow-ups - NUNCA debe fallar
        """
        argentina_tz = self.timezone
        current_time = datetime.now(argentina_tz)
        
        try:
            # FALLBACK 1: String con timezone expl√≠cito (preferido)
            if isinstance(dt_input, str):
                logger.info(f"üïê [TIMEZONE] Procesando string: {dt_input}")
                
                # Sub-fallback 1a: Timezone Argentina expl√≠cito
                if '-03:00' in dt_input:
                    result = datetime.fromisoformat(dt_input).astimezone(argentina_tz)
                    logger.info(f"‚úÖ [TIMEZONE] Fallback 1a exitoso: {result}")
                    return result
                
                # Sub-fallback 1b: UTC o timezone gen√©rico
                if dt_input.endswith('Z') or '+' in dt_input or ('-' in dt_input[-6:] and dt_input[-6:] != '-03:00'):
                    if dt_input.endswith('Z'):
                        dt_input = dt_input.replace('Z', '+00:00')
                    result = datetime.fromisoformat(dt_input).astimezone(argentina_tz)
                    logger.info(f"‚úÖ [TIMEZONE] Fallback 1b exitoso: {result}")
                    return result
                
                # Sub-fallback 1c: String sin timezone (asumir Argentina)
                try:
                    dt = datetime.fromisoformat(dt_input)
                    if dt.tzinfo is None:
                        result = argentina_tz.localize(dt)
                        logger.info(f"‚úÖ [TIMEZONE] Fallback 1c exitoso: {result}")
                        return result
                    else:
                        result = dt.astimezone(argentina_tz)
                        logger.info(f"‚úÖ [TIMEZONE] Fallback 1c-alt exitoso: {result}")
                        return result
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è [TIMEZONE] Fallback 1c fall√≥: {e}")
            
            # FALLBACK 2: Datetime object
            elif isinstance(dt_input, datetime):
                logger.info(f"üïê [TIMEZONE] Procesando datetime object: {dt_input} (tzinfo: {dt_input.tzinfo})")
                
                if dt_input.tzinfo is None:
                    result = argentina_tz.localize(dt_input)
                    logger.info(f"‚úÖ [TIMEZONE] Fallback 2a exitoso: {result}")
                    return result
                else:
                    result = dt_input.astimezone(argentina_tz)
                    logger.info(f"‚úÖ [TIMEZONE] Fallback 2b exitoso: {result}")
                    return result
            
            # FALLBACK 3: Tipo no soportado - log error pero continuar
            logger.error(f"‚ùå [TIMEZONE] Tipo no soportado: {type(dt_input)} = {dt_input}")
            
        except Exception as e:
            logger.error(f"‚ùå [TIMEZONE] Error en procesamiento principal: {e}")
        
        # üö® FALLBACK DE EMERGENCIA: Si todo falla, usar timestamp actual menos tiempo razonable
        emergency_timestamp = current_time - timedelta(minutes=30)
        logger.critical(f"üö® [TIMEZONE] FALLBACK DE EMERGENCIA activado: {emergency_timestamp}")
        logger.critical(f"üö® [TIMEZONE] Input original que fall√≥: {dt_input} (tipo: {type(dt_input)})")
        
        # Enviar alerta cr√≠tica (implementar despu√©s)
        # self._send_critical_alert(f"Timezone fallback emergency: {dt_input}")
        
        return emergency_timestamp
    
    def _has_real_conversation(self, context_data: dict) -> bool:
        """üö® NUEVO: Verificar si el usuario tiene conversaci√≥n real"""
        try:
            interaction_history = context_data.get('interaction_history', [])
            
            if not interaction_history:
                return False
            
            # Contar mensajes reales (user/assistant, no system internos)
            real_messages = 0
            for interaction in interaction_history:
                role = interaction.get('role', '')
                message = interaction.get('message', '')
                
                # Solo incluir mensajes reales de conversaci√≥n
                if role in ['user', 'assistant'] and message and not any(skip_phrase in message.lower() for skip_phrase in [
                    'escalado a humano', 'informaci√≥n faltante', 'necesita asistencia', 
                    'mostr√© categor√≠as', 'mostr√© productos'
                ]):
                    real_messages += 1
            
            # Necesita al menos 2 mensajes reales para justificar follow-up
            has_conversation = real_messages >= 2
            logger.debug(f"üìä Usuario: {real_messages} mensajes reales, follow-up justificado: {has_conversation}")
            
            return has_conversation
            
        except Exception as e:
            logger.error(f"‚ùå Error verificando conversaci√≥n real: {e}")
            return False
    
    def _check_migration_mode(self):
        """Verificar si el modo migraci√≥n est√° activo"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    # Buscar marca de migraci√≥n en configuraci√≥n
                    cursor.execute("""
                        SELECT config_value FROM follow_up_config 
                        WHERE config_key = 'migration_mode_until'
                    """)
                    result = cursor.fetchone()
                    
                    if result:
                        migration_until_str = result[0]
                        try:
                            self.migration_mode_until = datetime.fromisoformat(migration_until_str)
                            if self.migration_mode_until > datetime.now(self.timezone):
                                logger.info(f"üö® [MIGRATION] Modo migraci√≥n activo hasta: {self.migration_mode_until}")
                            else:
                                # Modo migraci√≥n expirado, limpiar
                                cursor.execute("""
                                    DELETE FROM follow_up_config 
                                    WHERE config_key = 'migration_mode_until'
                                """)
                                conn.commit()
                                self.migration_mode_until = None
                                logger.info("‚úÖ [MIGRATION] Modo migraci√≥n expirado y limpiado")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è [MIGRATION] Error parseando fecha de migraci√≥n: {e}")
                            self.migration_mode_until = None
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [MIGRATION] Error verificando modo migraci√≥n: {e}")
            self.migration_mode_until = None
    
    def _is_migration_mode_active(self) -> bool:
        """Verificar si el modo migraci√≥n est√° activo"""
        if self.migration_mode_until is None:
            return False
        
        current_time = datetime.now(self.timezone)
        is_active = current_time < self.migration_mode_until
        
        if not is_active and self.migration_mode_until:
            # Modo migraci√≥n expirado, limpiar
            logger.info("‚úÖ [MIGRATION] Modo migraci√≥n expirado autom√°ticamente")
            self.migration_mode_until = None
            # Limpiar de BD tambi√©n
            try:
                with psycopg2.connect(self.database_url) as conn:
                    with conn.cursor() as cursor:
                        cursor.execute("""
                            DELETE FROM follow_up_config 
                            WHERE config_key = 'migration_mode_until'
                        """)
                        conn.commit()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [MIGRATION] Error limpiando modo migraci√≥n: {e}")
        
        return is_active
        
    async def initialize(self):
        """Inicializar el scheduler"""
        try:
            # Configurar scheduler sin jobstore persistente (m√°s simple)
            executors = {
                'default': AsyncIOExecutor()
            }
            
            job_defaults = {
                'coalesce': True,
                'max_instances': 3,
                'misfire_grace_time': 300  # 5 minutos de gracia
            }
            
            self.scheduler = AsyncIOScheduler(
                executors=executors, 
                job_defaults=job_defaults,
                timezone=self.timezone
            )
            
            # Agregar job recurrente para procesar follow-ups pendientes
            self.scheduler.add_job(
                func=self._process_pending_followups,
                trigger='interval',
                minutes=1,  # Revisar cada minuto
                id='process_pending_followups',
                replace_existing=True
            )
            
            # Agregar job para detectar usuarios inactivos
            self.scheduler.add_job(
                func=self._check_inactive_users,
                trigger='interval',
                minutes=60,  # Revisar cada 1 hora
                id='check_inactive_users',
                replace_existing=True
            )
            
            # üö® SISTEMA DE FALLBACK CR√çTICO: Job de recuperaci√≥n cada 30 minutos
            self.scheduler.add_job(
                func=self._critical_followup_recovery,
                trigger='interval',
                minutes=30,  # Recuperaci√≥n cada 30 minutos
                id='critical_followup_recovery',
                replace_existing=True
            )
            
            # üö® SISTEMA DE FALLBACK: Verificaci√≥n hourly de usuarios sin follow-ups
            self.scheduler.add_job(
                func=self._emergency_followup_check,
                trigger='interval',
                minutes=15,  # Verificaci√≥n cada 15 minutos
                id='emergency_followup_check',
                replace_existing=True
            )
            
            # Agregar job de limpieza diaria
            self.scheduler.add_job(
                func=self._daily_cleanup,
                trigger='cron',
                hour=2,  # 2 AM
                id='daily_cleanup',
                replace_existing=True
            )
            
            logger.info("üìÖ Follow-up scheduler inicializado correctamente")
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando scheduler: {e}")
            raise
    
    def start(self):
        """Iniciar el scheduler"""
        if not self.scheduler:
            raise RuntimeError("Scheduler no inicializado. Llama initialize() primero.")
            
        self.scheduler.start()
        self.is_running = True
        logger.info("üöÄ Follow-up scheduler iniciado")
    
    def stop(self):
        """Detener el scheduler"""
        if self.scheduler and self.is_running:
            self.scheduler.shutdown(wait=False)
            self.is_running = False
            logger.info("‚èπÔ∏è Follow-up scheduler detenido")
    
    async def _process_pending_followups(self):
        """Procesar follow-ups pendientes que ya llegaron a su hora"""
        try:
            current_time = datetime.now(self.timezone)
            
            # TEMPORAL: Para diagn√≥stico
            logger.info(f"üîç [DEBUG] Buscando follow-ups pendientes antes de {current_time}")
            logger.info(f"üîç [DEBUG] Zona horaria: {self.timezone}")
            
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Buscar follow-ups que ya deben enviarse
                    cursor.execute("""
                        SELECT user_id, stage, scheduled_for, phone, status
                        FROM follow_up_jobs 
                        WHERE status = 'pending' 
                        AND scheduled_for <= %s
                        ORDER BY scheduled_for
                        LIMIT 10
                    """, (current_time,))
                    
                    pending_jobs = cursor.fetchall()
                    
                    # TEMPORAL: Para diagn√≥stico
                    logger.info(f"üîç [DEBUG] Follow-ups pendientes encontrados: {len(pending_jobs)}")
                    if pending_jobs:
                        logger.info(f"üîç [DEBUG] Primer job: user_id={pending_jobs[0]['user_id']}, stage={pending_jobs[0]['stage']}, scheduled_for={pending_jobs[0]['scheduled_for']}")
                    
                    for job in pending_jobs:
                        await self._execute_followup(job['user_id'], job['stage'])
                        
        except Exception as e:
            logger.error(f"‚ùå Error procesando follow-ups pendientes: {e}")

    async def _check_inactive_users(self):
        """Revisar usuarios inactivos y programar follow-ups"""
        try:
            logger.debug("üîç Revisando usuarios inactivos...")
            
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Buscar usuarios inactivos que no tienen follow-ups programados o recientes
                    query = """
                    SELECT DISTINCT cc.user_id, cc.last_interaction, cc.context_data
                    FROM conversation_contexts cc
                    LEFT JOIN follow_up_blacklist bl ON cc.user_id = bl.user_id
                    WHERE bl.user_id IS NULL  -- No est√° en blacklist
                    AND cc.last_interaction < %s  -- Inactivo por m√°s de 15 minutos
                    AND NOT EXISTS (  -- No tiene follow-ups pendientes recientes
                        SELECT 1 FROM follow_up_jobs fj 
                        WHERE fj.user_id = cc.user_id 
                        AND fj.status = 'pending'
                        AND fj.created_at > cc.last_interaction
                    )
                    AND NOT EXISTS (  -- No se envi√≥ follow-up en la √∫ltima hora (COOLDOWN)
                        SELECT 1 FROM follow_up_jobs fj2
                        WHERE fj2.user_id = cc.user_id
                        AND fj2.sent_at > %s  -- No enviado en los √∫ltimos 15 minutos
                    )
                    """
                    
                    # Detecci√≥n de usuarios inactivos despu√©s de 15 minutos
                    cutoff_time = datetime.now(self.timezone) - timedelta(minutes=15)
                    cooldown_time = datetime.now(self.timezone) - timedelta(minutes=15)  # Cooldown de 15 minutos
                    
                    logger.debug(f"üîç Checking inactive users since: {cutoff_time}")
                    logger.info(f"üïê Detectando usuarios inactivos por m√°s de 15 minutos")
                    logger.debug(f"üîç Cooldown time: {cooldown_time}")
                    logger.debug(f"üîç Timezone: {self.timezone}")
                    
                    cursor.execute(query, (cutoff_time, cooldown_time,))
                    inactive_users = cursor.fetchall()
                    
                    logger.info(f"üë• Encontrados {len(inactive_users)} usuarios inactivos")
                    
                    # TEMPORAL: Para diagn√≥stico
                    if inactive_users:
                        logger.info(f"üîç [DEBUG] Primer usuario inactivo: user_id={inactive_users[0]['user_id']}, last_interaction={inactive_users[0]['last_interaction']}")
                    else:
                        logger.info(f"üîç [DEBUG] No se encontraron usuarios inactivos")
                    
                    for user in inactive_users:
                        # TEMPORAL: Para diagn√≥stico
                        logger.info(f"üîç [DEBUG] Programando follow-ups para usuario inactivo: {user['user_id']}")
                        await self._schedule_user_followups(user)
                        
        except Exception as e:
            logger.error(f"‚ùå Error revisando usuarios inactivos: {e}")
    
    async def _schedule_user_followups(self, user_data: Dict[str, Any]):
        """üö® PROGRAMAR FOLLOW-UPS: Solo usuarios con conversaci√≥n real + validaci√≥n integral"""
        try:
            user_id = user_data['user_id']
            
            # üõ°Ô∏è VALIDACI√ìN INTEGRAL ANTI-SPAM
            validation = await self._comprehensive_followup_validation(user_id)
            if not validation['can_schedule']:
                logger.warning(f"üö´ [BLOCKED] {user_id} fall√≥ validaci√≥n: {validation['reasons']}")
                return
            
            # üîç VALIDACI√ìN CR√çTICA: Solo follow-ups para usuarios con conversaci√≥n real
            context_data = user_data.get('context_data', {})
            if not self._has_real_conversation(context_data):
                logger.info(f"‚è≠Ô∏è [SKIP] {user_id} sin conversaci√≥n real, omitiendo follow-ups")
                # Liberar lock si no hay conversaci√≥n real
                await self._release_recovery_lock(user_id)
                return
            
            logger.info(f"‚úÖ [VALID] {user_id} tiene conversaci√≥n real, programando follow-ups")
            
            # üö® SISTEMA DE FALLBACK TRIPLE para timestamp base
            last_interaction = None
            source_used = ""
            
            try:
                # FALLBACK 1: context_data.last_interaction (fuente preferida)
                context_data = user_data.get('context_data', {})
                if context_data and context_data.get('last_interaction'):
                    last_interaction = self._ensure_argentina_timezone(context_data['last_interaction'])
                    source_used = "context_data"
                    logger.info(f"‚úÖ [SCHEDULE] Fallback 1 usado para {user_id}: {last_interaction}")
                
                # FALLBACK 2: Campo directo user_data['last_interaction']
                elif user_data.get('last_interaction'):
                    last_interaction = self._ensure_argentina_timezone(user_data['last_interaction'])
                    source_used = "direct_field"
                    logger.info(f"‚úÖ [SCHEDULE] Fallback 2 usado para {user_id}: {last_interaction}")
                
                # FALLBACK 3: EMERGENCIA - timestamp actual menos 1 hora
                else:
                    last_interaction = datetime.now(self.timezone) - timedelta(hours=1)
                    source_used = "emergency"
                    logger.critical(f"üö® [SCHEDULE] FALLBACK DE EMERGENCIA para {user_id}: {last_interaction}")
                    
            except Exception as e:
                # FALLBACK √öLTIMO RECURSO
                logger.critical(f"üö® [SCHEDULE] ERROR en fallback para {user_id}: {e}")
                last_interaction = datetime.now(self.timezone) - timedelta(hours=2)
                source_used = "last_resort"
            
            # Obtener el √∫ltimo mensaje del usuario con fallback
            last_msg = None
            try:
                with psycopg2.connect(self.database_url) as conn:
                    with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                        cursor.execute("""
                            SELECT message, created_at 
                            FROM user_interactions 
                            WHERE user_id = %s AND role = 'user'
                            ORDER BY created_at DESC 
                            LIMIT 1
                        """, (user_id,))
                        last_msg = cursor.fetchone()
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [SCHEDULE] No se pudo obtener √∫ltimo mensaje para {user_id}: {e}")
            
            # LOGGING CR√çTICO para debugging
            logger.info(f"üìä [SCHEDULE] Usuario: {user_id}")
            logger.info(f"üìä [SCHEDULE] Fuente timestamp: {source_used}")
            logger.info(f"üìä [SCHEDULE] Last interaction: {last_interaction}")
            logger.info(f"üìä [SCHEDULE] Timezone: {self.timezone}")
            logger.info(f"üìä [SCHEDULE] √öltimo mensaje disponible: {last_msg is not None}")
            
            # Programar cada etapa del follow-up
            for stage, delay_hours in self.stage_delays.items():
                scheduled_time = last_interaction + timedelta(hours=delay_hours)
                
                # Stage 1 se env√≠a inmediatamente, otros stages respetan horario comercial
                if stage > 1:
                    scheduled_time = self._adjust_to_business_hours(scheduled_time)
                # Stage 1 no ajusta horario - se env√≠a inmediatamente cuando es hora
                
                await self._create_followup_job(
                    user_id=user_id,
                    stage=stage,
                    scheduled_for=scheduled_time,
                    context_snapshot=user_data.get('context_data', {}),
                    last_user_message=last_msg['message'] if last_msg else None
                )
            
            logger.info(f"üìÖ Follow-ups programados para usuario {user_id}")
            
        except Exception as e:
            logger.error(f"‚ùå Error programando follow-ups para {user_data.get('user_id')}: {e}")
    
    def _adjust_to_business_hours(self, dt: datetime) -> datetime:
        """Ajustar fecha/hora al horario comercial permitido"""
        # Convertir a timezone local
        if dt.tzinfo is None:
            dt = self.timezone.localize(dt)
        else:
            dt = dt.astimezone(self.timezone)
        
        # Ajustar d√≠a de la semana
        while dt.weekday() + 1 not in self.allowed_weekdays:  # weekday() es 0-6
            dt += timedelta(days=1)
            dt = dt.replace(hour=self.start_hour, minute=0, second=0)
        
        # Ajustar hora del d√≠a
        if dt.hour < self.start_hour:
            dt = dt.replace(hour=self.start_hour, minute=0, second=0)
        elif dt.hour >= self.end_hour:
            # Mover al siguiente d√≠a h√°bil
            dt += timedelta(days=1)
            dt = dt.replace(hour=self.start_hour, minute=0, second=0)
            # Verificar de nuevo el d√≠a de la semana
            while dt.weekday() + 1 not in self.allowed_weekdays:
                dt += timedelta(days=1)
        
        return dt
    
    async def _create_followup_job(self, user_id: str, stage: int, 
                                  scheduled_for: datetime, context_snapshot: Dict,
                                  last_user_message: Optional[str] = None):
        """Crear un trabajo de follow-up en la base de datos con contexto completo"""
        try:
            from psycopg2.extras import Json
            
            # Enriquecer context_snapshot con historial de interacciones completo
            enriched_context = await self._enrich_context_with_interactions(user_id, context_snapshot)
            
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    # üö® CORREGIDO: Obtener el tel√©fono del contexto con l√≥gica robusta
                    phone = enriched_context.get('phone')
                    if not phone and user_id.startswith('whatsapp_'):
                        # Extraer tel√©fono del user_id
                        phone = user_id.replace('whatsapp_', '')
                        logger.info(f"üìû [PHONE] Extra√≠do de user_id: {phone}")
                    elif phone:
                        logger.info(f"üìû [PHONE] Obtenido del contexto: {phone}")
                    
                    # Validaci√≥n final para evitar NULL y casos edge
                    if not phone or phone in ['null', 'None', '', 'undefined', '0']:
                        logger.error(f"‚ùå [PHONE] Tel√©fono inv√°lido para {user_id}: '{phone}', saltando follow-up")
                        return  # No crear follow-up sin tel√©fono v√°lido
                    
                    # Validar formato b√°sico de tel√©fono (solo n√∫meros, m√≠nimo 10 d√≠gitos)
                    if not phone.isdigit() or len(phone) < 10:
                        logger.error(f"‚ùå [PHONE] Formato de tel√©fono inv√°lido para {user_id}: '{phone}', saltando follow-up")
                        return
                    
                    # TEMPORAL: Para diagn√≥stico
                    logger.info(f"üîç [DEBUG] Creando follow-up job: user_id={user_id}, stage={stage}, scheduled_for={scheduled_for}, phone={phone}")
                    logger.info(f"üîç [DEBUG] Context snapshot incluye {len(enriched_context.get('interaction_history', []))} interacciones")
                    
                    cursor.execute("""
                        INSERT INTO follow_up_jobs 
                        (user_id, phone, stage, scheduled_for, context_snapshot, last_user_message)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        ON CONFLICT (user_id, stage) DO UPDATE SET
                            scheduled_for = EXCLUDED.scheduled_for,
                            context_snapshot = EXCLUDED.context_snapshot,
                            status = 'pending'
                    """, (user_id, phone, stage, scheduled_for, 
                          Json(enriched_context), last_user_message))
                    
                    logger.debug(f"üìã Follow-up programado en BD: usuario {user_id} etapa {stage} para {scheduled_for}")
                    
        except Exception as e:
            logger.error(f"‚ùå Error creando job de follow-up: {e}")
    
    async def _enrich_context_with_interactions(self, user_id: str, context_snapshot: Dict) -> Dict:
        """Enriquecer context snapshot con historial completo de interacciones"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Obtener √∫ltimas 20 interacciones
                    cursor.execute("""
                        SELECT role, message, created_at, metadata
                        FROM user_interactions 
                        WHERE user_id = %s 
                        ORDER BY created_at DESC 
                        LIMIT 20
                    """, (user_id,))
                    
                    interactions = [dict(row) for row in cursor.fetchall()]
                    interactions.reverse()  # Orden cronol√≥gico
                    
                    # Enriquecer contexto
                    enriched = dict(context_snapshot)
                    enriched['interaction_history'] = interactions
                    
                    logger.debug(f"‚úÖ Context enriched: {len(interactions)} interacciones agregadas")
                    return enriched
                    
        except Exception as e:
            logger.error(f"‚ùå Error enriching context: {e}")
            return context_snapshot
    
    def _get_stage_description(self, stage: int) -> str:
        """Obtener descripci√≥n de la etapa"""
        descriptions = {
            1: "Recordatorio inicial (15 minutos)",
            2: "Seguimiento temprano (1 hora)",
            3: "Seguimiento del d√≠a siguiente",
            4: "Recordatorio a 48 horas",
            5: "Seguimiento a 3 d√≠as",
            6: "Recordatorio a 4 d√≠as",
            7: "√öltimo intento (5 d√≠as)"
        }
        return descriptions.get(stage, f"Etapa {stage}")
    
    async def _execute_followup(self, user_id: str, stage: int):
        """Ejecutar un follow-up espec√≠fico"""
        try:
            logger.info(f"üì§ Ejecutando follow-up etapa {stage} para usuario {user_id}")
            
            # Verificar si el usuario sigue inactivo
            is_inactive = await self._is_user_still_inactive(user_id)
            logger.info(f"üîç [DEBUG] Usuario {user_id} inactivo: {is_inactive}")
            
            if is_inactive:
                # Importar el manager para enviar el mensaje
                from .follow_up_manager import FollowUpManager
                
                manager = FollowUpManager(
                    database_url=self.database_url,
                    evolution_api_url=self.evolution_api_url,
                    evolution_token=self.evolution_token,
                    instance_name=self.instance_name,
                    openai_api_key=self.openai_api_key
                )
                success = await manager.send_followup_message(user_id, stage)
                
                if success:
                    await self._mark_job_completed(user_id, stage)
                    logger.info(f"‚úÖ Follow-up etapa {stage} enviado a {user_id}")
                else:
                    await self._mark_job_failed(user_id, stage)
                    logger.warning(f"‚ö†Ô∏è Fall√≥ follow-up etapa {stage} para {user_id}")
            else:
                # Usuario ya est√° activo, cancelar follow-ups restantes
                await self._cancel_remaining_followups(user_id)
                logger.info(f"üîÑ Usuario {user_id} activo, cancelando follow-ups restantes")
                
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando follow-up: {e}")
            await self._mark_job_failed(user_id, stage)
    
    async def _is_user_still_inactive(self, user_id: str) -> bool:
        """
        üö® VERSI√ìN CR√çTICA: Verificar inactividad con m√∫ltiples fallbacks
        NUNCA debe fallar - vital para follow-ups
        """
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    cursor.execute("""
                        SELECT last_interaction, context_data
                        FROM conversation_contexts 
                        WHERE user_id = %s
                    """, (user_id,))
                    
                    result = cursor.fetchone()
                    if not result:
                        logger.warning(f"‚ö†Ô∏è [INACTIVE] Usuario {user_id} no encontrado en BD")
                        # FALLBACK: Usuario no encontrado = considera inactivo por seguridad
                        return True
                    
                    # SISTEMA DE FALLBACK TRIPLE para timestamp
                    last_interaction = None
                    source_used = ""
                    
                    try:
                        # FALLBACK 1: context_data.last_interaction (fuente preferida)
                        context_data = result.get('context_data', {})
                        if context_data and context_data.get('last_interaction'):
                            last_interaction = self._ensure_argentina_timezone(context_data['last_interaction'])
                            source_used = "context_data"
                            logger.info(f"‚úÖ [INACTIVE] Fallback 1 (context_data) usado para {user_id}: {last_interaction}")
                        
                        # FALLBACK 2: Campo directo last_interaction
                        elif result['last_interaction']:
                            last_interaction = self._ensure_argentina_timezone(result['last_interaction'])
                            source_used = "direct_field"
                            logger.info(f"‚úÖ [INACTIVE] Fallback 2 (direct_field) usado para {user_id}: {last_interaction}")
                        
                        # FALLBACK 3: EMERGENCIA - usar timestamp actual menos 1 hora
                        else:
                            last_interaction = datetime.now(self.timezone) - timedelta(hours=1)
                            source_used = "emergency_fallback"
                            logger.critical(f"üö® [INACTIVE] FALLBACK DE EMERGENCIA para {user_id}: {last_interaction}")
                            logger.critical(f"üö® [INACTIVE] Datos originales - context_data: {context_data}, direct: {result['last_interaction']}")
                    
                    except Exception as e:
                        # FALLBACK DE √öLTIMO RECURSO
                        logger.critical(f"üö® [INACTIVE] ERROR en fallback, usando √öLTIMO RECURSO para {user_id}: {e}")
                        last_interaction = datetime.now(self.timezone) - timedelta(hours=2)
                        source_used = "last_resort"
                    
                    # Verificar inactividad con cutoff de 15 minutos
                    cutoff = datetime.now(self.timezone) - timedelta(minutes=15)
                    is_inactive = last_interaction < cutoff
                    
                    # LOGGING DETALLADO para debugging
                    logger.info(f"üìä [INACTIVE] Usuario: {user_id}")
                    logger.info(f"üìä [INACTIVE] Fuente timestamp: {source_used}")
                    logger.info(f"üìä [INACTIVE] Last interaction: {last_interaction}")
                    logger.info(f"üìä [INACTIVE] Cutoff time: {cutoff}")
                    logger.info(f"üìä [INACTIVE] Es inactivo: {is_inactive}")
                    logger.info(f"üìä [INACTIVE] Diferencia minutos: {(cutoff - last_interaction).total_seconds() / 60:.1f}")
                    
                    # VALIDACI√ìN CR√çTICA: Si el timestamp es muy futuro, algo est√° mal
                    current_time = datetime.now(self.timezone)
                    if last_interaction > current_time + timedelta(minutes=5):
                        logger.critical(f"üö® [INACTIVE] TIMESTAMP FUTURO DETECTADO para {user_id}: {last_interaction}")
                        # En caso de timestamp futuro, considera inactivo por seguridad
                        return True
                    
                    return is_inactive
                    
        except Exception as e:
            logger.critical(f"üö® [INACTIVE] ERROR CR√çTICO verificando inactividad {user_id}: {e}")
            # FALLBACK FINAL: En caso de error, considera inactivo (mejor enviar que no enviar)
            return True
    
    async def _cancel_remaining_followups(self, user_id: str):
        """Cancelar follow-ups restantes de un usuario"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    # Cancelar en la base de datos
                    cursor.execute("""
                        UPDATE follow_up_jobs 
                        SET status = 'cancelled', processed_at = %s
                        WHERE user_id = %s AND status = 'pending'
                    """, (datetime.now(self.timezone), user_id))
                    
                    cancelled_count = cursor.rowcount
                    
                    logger.info(f"üö´ Cancelados {cancelled_count} follow-ups para {user_id}")
                    
        except Exception as e:
            logger.error(f"‚ùå Error cancelando follow-ups: {e}")
    
    async def _mark_job_completed(self, user_id: str, stage: int):
        """Marcar job como completado"""
        await self._update_job_status(user_id, stage, 'sent')
    
    async def _mark_job_failed(self, user_id: str, stage: int):
        """Marcar job como fallido"""
        await self._update_job_status(user_id, stage, 'failed')
    
    async def _update_job_status(self, user_id: str, stage: int, status: str):
        """Actualizar estado de un job"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        UPDATE follow_up_jobs 
                        SET status = %s, processed_at = %s, attempts = attempts + 1
                        WHERE user_id = %s AND stage = %s
                    """, (status, datetime.now(self.timezone), user_id, stage))
                    
        except Exception as e:
            logger.error(f"‚ùå Error actualizando status del job: {e}")
    
    async def _daily_cleanup(self):
        """Limpieza diaria de trabajos antiguos"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    # Limpiar trabajos completados/fallidos de m√°s de 30 d√≠as
                    cursor.execute("""
                        DELETE FROM follow_up_jobs 
                        WHERE created_at < %s 
                        AND status IN ('sent', 'cancelled', 'failed')
                    """, (datetime.now(self.timezone) - timedelta(days=30),))
                    
                    deleted_count = cursor.rowcount
                    logger.info(f"üßπ Limpieza diaria: {deleted_count} jobs antiguos eliminados")
                    
        except Exception as e:
            logger.error(f"‚ùå Error en limpieza diaria: {e}")
    
    async def schedule_user_followups(self, user_id: str, phone: str, 
                                    context_data: Dict[str, Any],
                                    last_message: Optional[str] = None):
        """API p√∫blica para programar follow-ups de un usuario espec√≠fico"""
        try:
            # Cancelar follow-ups existentes primero
            await self._cancel_remaining_followups(user_id)
            
            base_time = datetime.now(self.timezone)
            
            for stage, delay_hours in self.stage_delays.items():
                scheduled_time = base_time + timedelta(hours=delay_hours)
                
                # Stage 1 se env√≠a inmediatamente, otros stages respetan horario comercial  
                if stage > 1:
                    scheduled_time = self._adjust_to_business_hours(scheduled_time)
                
                await self._create_followup_job(
                    user_id=user_id,
                    stage=stage,
                    scheduled_for=scheduled_time,
                    context_snapshot=context_data,
                    last_user_message=last_message
                )
            
            logger.info(f"üìÖ Follow-ups programados manualmente para {user_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error programando follow-ups manuales: {e}")
            return False
    
    async def cancel_user_followups(self, user_id: str):
        """Cancelar todos los follow-ups de un usuario"""
        await self._cancel_remaining_followups(user_id)
    
    async def get_pending_jobs(self) -> List[Dict[str, Any]]:
        """Obtener lista de trabajos pendientes"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    cursor.execute("""
                        SELECT user_id, stage, scheduled_for, created_at, attempts
                        FROM follow_up_jobs 
                        WHERE status = 'pending'
                        ORDER BY scheduled_for
                    """)
                    
                    return [dict(row) for row in cursor.fetchall()]
                    
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo trabajos pendientes: {e}")
            return []
    
    async def get_scheduler_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas del scheduler"""
        try:
            jobs = await self.get_pending_jobs()
            
            return {
                "is_running": self.is_running,
                "pending_jobs": len(jobs),
                "next_job": jobs[0]['scheduled_for'] if jobs else None,
                "scheduler_jobs": len(self.scheduler.get_jobs()) if self.scheduler else 0
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estad√≠sticas: {e}")
            return {"error": str(e)}
    
    async def _critical_followup_recovery(self):
        """üö® SISTEMA DE RECUPERACI√ìN CR√çTICA: Re-programa follow-ups fallidos o perdidos"""
        try:
            # üõ°Ô∏è PROTECCI√ìN ANTI-DUPLICACI√ìN: Verificar modo migraci√≥n
            if self._is_migration_mode_active():
                logger.info("üö® [RECOVERY] SALTANDO recovery - modo migraci√≥n activo para prevenir duplicaci√≥n")
                return
            
            logger.info("üö® [RECOVERY] Iniciando recuperaci√≥n cr√≠tica de follow-ups")
            
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Buscar jobs fallidos de las √∫ltimas 24 horas que deber√≠an reintentarse
                    cursor.execute("""
                        SELECT user_id, stage, scheduled_for, attempts
                        FROM follow_up_jobs 
                        WHERE status = 'failed' 
                        AND attempts < 3
                        AND scheduled_for < %s
                        AND created_at > %s
                    """, (
                        datetime.now(self.timezone),
                        datetime.now(self.timezone) - timedelta(hours=24)
                    ))
                    
                    failed_jobs = cursor.fetchall()
                    
                    logger.info(f"üö® [RECOVERY] Encontrados {len(failed_jobs)} jobs fallidos para recuperar")
                    
                    for job in failed_jobs:
                        try:
                            # Resetear job para reintento
                            cursor.execute("""
                                UPDATE follow_up_jobs 
                                SET status = 'pending', 
                                    scheduled_for = %s,
                                    processed_at = NULL
                                WHERE user_id = %s AND stage = %s
                            """, (
                                datetime.now(self.timezone) + timedelta(minutes=5),  # Reintentar en 5 minutos
                                job['user_id'], 
                                job['stage']
                            ))
                            
                            logger.info(f"‚úÖ [RECOVERY] Job recuperado: {job['user_id']} stage {job['stage']}")
                            
                        except Exception as e:
                            logger.error(f"‚ùå [RECOVERY] Error recuperando job {job['user_id']}: {e}")
                    
                    conn.commit()
                    
        except Exception as e:
            logger.critical(f"üö® [RECOVERY] ERROR CR√çTICO en recuperaci√≥n: {e}")
    
    async def _emergency_followup_check(self):
        """üö® VERIFICACI√ìN DE EMERGENCIA: Encuentra usuarios que deber√≠an tener follow-ups pero no los tienen"""
        try:
            logger.info("üö® [EMERGENCY] Verificaci√≥n de emergencia de follow-ups faltantes")
            
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Buscar usuarios inactivos sin follow-ups programados
                    cursor.execute("""
                        SELECT cc.user_id, cc.last_interaction, cc.context_data
                        FROM conversation_contexts cc
                        LEFT JOIN follow_up_blacklist bl ON cc.user_id = bl.user_id
                        WHERE bl.user_id IS NULL  -- No en blacklist
                        AND cc.last_interaction < %s  -- Inactivo por m√°s de 2 horas
                        AND NOT EXISTS (  -- Sin follow-ups pendientes
                            SELECT 1 FROM follow_up_jobs fj 
                            WHERE fj.user_id = cc.user_id 
                            AND fj.status = 'pending'
                        )
                        AND NOT EXISTS (  -- Sin follow-ups enviados recientemente
                            SELECT 1 FROM follow_up_jobs fj2
                            WHERE fj2.user_id = cc.user_id
                            AND fj2.created_at > %s
                        )
                        LIMIT 10  -- Procesar m√°ximo 10 por vez
                    """, (
                        datetime.now(self.timezone) - timedelta(hours=2),  # 2 horas inactivo
                        datetime.now(self.timezone) - timedelta(hours=6)   # Sin follow-ups en 6 horas
                    ))
                    
                    missing_followups = cursor.fetchall()
                    
                    logger.info(f"üö® [EMERGENCY] Encontrados {len(missing_followups)} usuarios sin follow-ups")
                    
                    for user in missing_followups:
                        try:
                            # Programar follow-ups de emergencia
                            logger.critical(f"üö® [EMERGENCY] Programando follow-ups de emergencia para {user['user_id']}")
                            await self._schedule_user_followups(user)
                            
                        except Exception as e:
                            logger.critical(f"üö® [EMERGENCY] Error programando follow-ups de emergencia para {user['user_id']}: {e}")
                    
        except Exception as e:
            logger.critical(f"üö® [EMERGENCY] ERROR CR√çTICO en verificaci√≥n de emergencia: {e}")
    
    # üõ°Ô∏è RATE LIMITING FUNCTIONS - Anti-Spam Protection
    
    async def _check_daily_rate_limit(self, user_id: str) -> bool:
        """üõ°Ô∏è CRITICAL: Verificar rate limit diario - m√°ximo 1 follow-up por d√≠a"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Reset autom√°tico si cambi√≥ el d√≠a
                    cursor.execute("""
                        UPDATE follow_up_rate_limits 
                        SET daily_count = 0, reset_date = CURRENT_DATE 
                        WHERE user_id = %s AND reset_date < CURRENT_DATE
                    """, (user_id,))
                    
                    # Verificar l√≠mite actual
                    cursor.execute("""
                        SELECT daily_count, last_followup_sent, reset_date
                        FROM follow_up_rate_limits 
                        WHERE user_id = %s
                    """, (user_id,))
                    
                    result = cursor.fetchone()
                    
                    if not result:
                        # Primera vez - crear registro
                        cursor.execute("""
                            INSERT INTO follow_up_rate_limits (user_id, daily_count, reset_date)
                            VALUES (%s, 0, CURRENT_DATE)
                        """, (user_id,))
                        conn.commit()
                        logger.info(f"üõ°Ô∏è [RATE_LIMIT] Nuevo usuario registrado: {user_id}")
                        return True
                    
                    daily_count = result['daily_count']
                    last_sent = result['last_followup_sent']
                    reset_date = result['reset_date']
                    
                    # REGLA CR√çTICA: M√°ximo 1 follow-up por d√≠a
                    if daily_count >= 1:
                        logger.warning(f"üõ°Ô∏è [RATE_LIMIT] BLOQUEADO - Usuario {user_id} ya envi√≥ {daily_count} follow-ups hoy ({reset_date})")
                        logger.warning(f"üõ°Ô∏è [RATE_LIMIT] √öltimo env√≠o: {last_sent}")
                        return False
                    
                    logger.info(f"üõ°Ô∏è [RATE_LIMIT] Usuario {user_id} puede enviar follow-up (count: {daily_count})")
                    return True
                    
        except Exception as e:
            logger.error(f"‚ùå [RATE_LIMIT] Error verificando rate limit para {user_id}: {e}")
            # En caso de error, ser conservador y DENEGAR
            return False
    
    async def _increment_daily_count(self, user_id: str) -> bool:
        """üõ°Ô∏è Incrementar contador diario despu√©s de env√≠o exitoso"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO follow_up_rate_limits (user_id, daily_count, last_followup_sent, reset_date)
                        VALUES (%s, 1, CURRENT_TIMESTAMP, CURRENT_DATE)
                        ON CONFLICT (user_id) 
                        DO UPDATE SET 
                            daily_count = follow_up_rate_limits.daily_count + 1,
                            last_followup_sent = CURRENT_TIMESTAMP,
                            updated_at = CURRENT_TIMESTAMP
                    """, (user_id,))
                    
                    conn.commit()
                    logger.info(f"üõ°Ô∏è [RATE_LIMIT] Contador incrementado para {user_id}")
                    return True
                    
        except Exception as e:
            logger.error(f"‚ùå [RATE_LIMIT] Error incrementando contador para {user_id}: {e}")
            return False
    
    async def _acquire_recovery_lock(self, user_id: str, recovery_type: str = 'critical', lock_minutes: int = 30) -> bool:
        """üîí Obtener lock para recovery operation - prevenir race conditions"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    # Limpiar locks expirados primero
                    cursor.execute("""
                        DELETE FROM follow_up_recovery_locks 
                        WHERE locked_until < CURRENT_TIMESTAMP
                    """)
                    
                    # Verificar si hay lock activo
                    cursor.execute("""
                        SELECT recovery_type, locked_until, last_recovery_attempt
                        FROM follow_up_recovery_locks 
                        WHERE user_id = %s AND locked_until > CURRENT_TIMESTAMP
                    """, (user_id,))
                    
                    existing_lock = cursor.fetchone()
                    if existing_lock:
                        logger.info(f"üîí [RECOVERY_LOCK] Usuario {user_id} tiene lock activo ({existing_lock['recovery_type']}) hasta {existing_lock['locked_until']}")
                        return False
                    
                    # Obtener lock
                    cursor.execute("""
                        INSERT INTO follow_up_recovery_locks (user_id, recovery_type, locked_until)
                        VALUES (%s, %s, CURRENT_TIMESTAMP + INTERVAL '%s minutes')
                        ON CONFLICT (user_id) 
                        DO UPDATE SET 
                            recovery_type = %s,
                            locked_until = CURRENT_TIMESTAMP + INTERVAL '%s minutes',
                            last_recovery_attempt = CURRENT_TIMESTAMP
                    """, (user_id, recovery_type, lock_minutes, recovery_type, lock_minutes))
                    
                    conn.commit()
                    logger.info(f"üîí [RECOVERY_LOCK] Lock adquirido para {user_id} ({recovery_type}) por {lock_minutes} minutos")
                    return True
                    
        except Exception as e:
            logger.error(f"‚ùå [RECOVERY_LOCK] Error adquiriendo lock para {user_id}: {e}")
            return False
    
    async def _release_recovery_lock(self, user_id: str):
        """üîì Liberar lock de recovery operation"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        DELETE FROM follow_up_recovery_locks 
                        WHERE user_id = %s
                    """, (user_id,))
                    
                    conn.commit()
                    logger.info(f"üîì [RECOVERY_LOCK] Lock liberado para {user_id}")
                    
        except Exception as e:
            logger.error(f"‚ùå [RECOVERY_LOCK] Error liberando lock para {user_id}: {e}")
    
    async def _check_existing_pending_jobs(self, user_id: str, stage: int = None) -> bool:
        """üîç Verificar si ya existen jobs pendientes para evitar duplicados"""
        try:
            with psycopg2.connect(self.database_url) as conn:
                with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                    if stage:
                        cursor.execute("""
                            SELECT COUNT(*) as count
                            FROM follow_up_jobs 
                            WHERE user_id = %s AND stage = %s AND status = 'pending'
                        """, (user_id, stage))
                    else:
                        cursor.execute("""
                            SELECT COUNT(*) as count
                            FROM follow_up_jobs 
                            WHERE user_id = %s AND status = 'pending'
                        """, (user_id,))
                    
                    result = cursor.fetchone()
                    pending_count = result['count'] if result else 0
                    
                    if pending_count > 0:
                        logger.info(f"üîç [DUPLICATE_CHECK] Usuario {user_id} tiene {pending_count} jobs pendientes (stage: {stage or 'all'})")
                        return True
                    
                    return False
                    
        except Exception as e:
            logger.error(f"‚ùå [DUPLICATE_CHECK] Error verificando jobs pendientes para {user_id}: {e}")
            return True  # En caso de error, asumir que hay duplicados
    
    async def _comprehensive_followup_validation(self, user_id: str, stage: int = None) -> dict:
        """üõ°Ô∏è VALIDACI√ìN INTEGRAL antes de programar follow-ups"""
        validation_result = {
            'can_schedule': False,
            'reasons': [],
            'rate_limit_ok': False,
            'no_pending_jobs': False,
            'lock_acquired': False,
            'user_id': user_id
        }
        
        try:
            # 1. Verificar rate limit diario
            rate_limit_ok = await self._check_daily_rate_limit(user_id)
            validation_result['rate_limit_ok'] = rate_limit_ok
            if not rate_limit_ok:
                validation_result['reasons'].append('rate_limit_exceeded')
            
            # 2. Verificar jobs pendientes existentes
            has_pending = await self._check_existing_pending_jobs(user_id, stage)
            validation_result['no_pending_jobs'] = not has_pending
            if has_pending:
                validation_result['reasons'].append('pending_jobs_exist')
            
            # 3. Intentar obtener lock de recovery
            lock_acquired = await self._acquire_recovery_lock(user_id, 'scheduled', 60)
            validation_result['lock_acquired'] = lock_acquired
            if not lock_acquired:
                validation_result['reasons'].append('recovery_lock_active')
            
            # 4. Verificar blacklist (usar funci√≥n existente si existe)
            # TODO: Agregar verificaci√≥n de blacklist si no est√° implementada
            
            # RESULTADO FINAL
            validation_result['can_schedule'] = (
                rate_limit_ok and 
                not has_pending and 
                lock_acquired
            )
            
            if validation_result['can_schedule']:
                logger.info(f"‚úÖ [VALIDATION] Usuario {user_id} puede programar follow-ups")
            else:
                logger.warning(f"üö´ [VALIDATION] Usuario {user_id} NO puede programar follow-ups: {validation_result['reasons']}")
            
            return validation_result
            
        except Exception as e:
            logger.error(f"‚ùå [VALIDATION] Error en validaci√≥n integral para {user_id}: {e}")
            validation_result['reasons'].append('validation_error')
            return validation_result