# ðŸ”§ **GUÃA: APLICACIÃ“N MANUAL DE FEEDBACKS**

## ðŸ“‹ **Workflow Semanal: Feedback â†’ Mejoras**

### **ðŸ—“ï¸ Lunes: AnÃ¡lisis de Feedback**

#### **1. Ejecutar Script de AnÃ¡lisis**
```python
# Crear script: weekly_analysis.py
import sqlite3
import pandas as pd
from datetime import datetime, timedelta

def analyze_weekly_feedback():
    conn = sqlite3.connect('bot_feedback.db')
    
    # Feedback de los Ãºltimos 7 dÃ­as
    query = """
    SELECT rating, category, feedback_text, message, timestamp
    FROM conversations 
    WHERE timestamp > datetime('now', '-7 days')
    AND rating IS NOT NULL
    ORDER BY rating ASC, timestamp DESC
    """
    
    df = pd.read_sql_query(query, conn)
    
    # AnÃ¡lisis por categorÃ­a
    issues = df.groupby('category').agg({
        'rating': ['count', 'mean'],
        'feedback_text': 'first'
    }).round(2)
    
    print("ðŸš¨ ISSUES PRIORITARIOS (Rating â‰¤ 3):")
    critical = issues[issues[('rating', 'mean')] <= 3]
    for category, data in critical.iterrows():
        print(f"\nðŸ“Œ {category}")
        print(f"   Casos: {data[('rating', 'count')]}")
        print(f"   Rating: {data[('rating', 'mean')]}/5")
        print(f"   Ejemplo: {data[('feedback_text', 'first')][:100]}...")
    
    conn.close()
    return critical

# Ejecutar cada lunes
if __name__ == "__main__":
    analyze_weekly_feedback()
```

#### **2. Priorizar Issues**
```python
# Matriz de priorizaciÃ³n
PRIORITY_MATRIX = {
    (5, 1): "ðŸš¨ CRÃTICO",      # Frecuencia alta, rating muy bajo
    (3, 1): "ðŸ”¥ ALTO",         # Frecuencia media, rating muy bajo  
    (5, 2): "âš¡ MEDIO",        # Frecuencia alta, rating bajo
    (1, 1): "ðŸ“‹ BAJO"          # Frecuencia baja, rating muy bajo
}

def prioritize_issues(issues_df):
    for category, data in issues_df.iterrows():
        freq = min(5, data[('rating', 'count')])  # MÃ¡ximo 5
        rating = int(data[('rating', 'mean')])
        priority = PRIORITY_MATRIX.get((freq, rating), "ðŸ“‹ REVISAR")
        print(f"{priority}: {category}")
```

---

### **ðŸ› ï¸ Martes-MiÃ©rcoles: IdentificaciÃ³n y AplicaciÃ³n de Fixes**

#### **Mapeo: Feedback â†’ Archivo â†’ Fix**

##### **1. "InformaciÃ³n Incorrecta"**
```python
# Archivo: Entrenamiento/Entrenamiento-Productos.txt
# Fix: Actualizar datos especÃ­ficos

# ANTES:
"Los envÃ­os tardan 3-5 dÃ­as hÃ¡biles"

# DESPUÃ‰S (si feedback dice que tardan mÃ¡s):
"Los envÃ­os tardan 5-7 dÃ­as hÃ¡biles via OCA/Andreani"

# CÃ³digo en royal_agents/training_parser.py - lÃ­nea ~50
# Verificar que parse correctamente el nuevo texto
```

##### **2. "No Encuentra Productos"**
```python
# Archivo: royal_agents/woocommerce_mcp_tools.py
# Fix: Mejorar parÃ¡metros de bÃºsqueda

# ANTES (lÃ­nea ~120):
def search_products(query, limit=10):
    params = {'search': query, 'per_page': limit}

# DESPUÃ‰S:
def search_products(query, limit=10):
    params = {
        'search': query, 
        'per_page': limit,
        'status': 'publish',
        'stock_status': 'instock'  # Solo productos disponibles
    }
    
    # BÃºsqueda fuzzy adicional si no hay resultados
    if not results:
        fuzzy_params = {
            'search': query.replace(' ', '%'),  # BÃºsqueda parcial
            'per_page': limit
        }
        results = make_request('products', fuzzy_params)
```

##### **3. "Tono Inadecuado"**
```python
# Archivo: royal_agents/royal_agent_contextual.py
# Fix: Ajustar system prompt (lÃ­nea ~80)

# ANTES:
"Sos entusiasta y energÃ©tico"

# DESPUÃ‰S (si feedback dice "muy agresivo"):
"Sos entusiasta pero relajado, nunca presiones al cliente"

# O si dice "muy informal":
"UsÃ¡s un tono profesional pero amigable, argentino pero no coloquial"
```

##### **4. "Escala Demasiado RÃ¡pido"**
```python
# Archivo: royal_agents/contextual_tools.py
# Fix: Ajustar thresholds (lÃ­nea ~45)

# ANTES:
if len(frustration_found) >= 1:
    frustration_level = 2

# DESPUÃ‰S:
if len(frustration_found) >= 2:  # MÃ¡s tolerante
    frustration_level = 2

# O ajustar palabras de frustraciÃ³n:
frustration_indicators = [
    'no funciona', 'terrible',  # Mantener crÃ­ticas
    # 'confundido', 'perdido'   # Remover palabras suaves
]
```

##### **5. "Respuestas Confusas"**
```python
# Archivo: royal_agents/contextual_tools.py
# Fix: Mejorar lÃ³gica de herramientas

# ANTES:
def get_product_info_with_context():
    if not products:
        return "No encontrÃ© productos"

# DESPUÃ‰S:
def get_product_info_with_context():
    if not products:
        # Activar HITL en lugar de dar respuesta negativa
        handle_missing_information_hitl("product", product_name)
        return "Dame un momento que chequeo opciones similares ðŸ‘"
```

---

### **ðŸ§ª Jueves: Testing de Cambios**

#### **Script de Testing Dirigido**
```python
# Crear: test_fixes.py
def test_specific_fix(issue_category, test_messages):
    """Testa un fix especÃ­fico con mensajes que causaron el problema"""
    
    from royal_agents import run_contextual_conversation_sync
    
    print(f"\nðŸ§ª Testing fix para: {issue_category}")
    
    for i, message in enumerate(test_messages, 1):
        print(f"\n--- Test {i} ---")
        print(f"Input: {message}")
        
        response = run_contextual_conversation_sync("test_user", message)
        print(f"Output: {response[:200]}...")
        
        # EvaluaciÃ³n manual
        rating = input("Rating 1-5: ")
        if int(rating) >= 4:
            print("âœ… Fix exitoso")
        else:
            print("âŒ Fix necesita ajustes")

# Ejemplos de uso:
test_specific_fix("No encuentra productos", [
    "Â¿tenÃ©s anillos de plata?",
    "busco cadenas doradas",
    "hay relojes casio?"
])

test_specific_fix("Tono inadecuado", [
    "no me convence este producto",
    "creo que es muy caro",
    "no sÃ© si me sirve"
])
```

---

### **ðŸš€ Viernes: Deploy y Monitoreo**

#### **1. Deploy de Cambios**
```bash
# Testing local final
streamlit run bot_testing_app.py --server.port 8501

# Test con algunos mensajes reales del feedback
# Si todo OK, deploy:

# OpciÃ³n A: Railway
python deploy.py  # Seleccionar opciÃ³n 1

# OpciÃ³n B: Commit y push para auto-deploy
git add .
git commit -m "Fix: [descripciÃ³n del problema resuelto]"
git push origin main
```

#### **2. Monitoreo Post-Deploy**
```python
# Script: monitor_post_deploy.py
def monitor_improvement():
    """Monitorea si el fix mejorÃ³ las mÃ©tricas"""
    
    # Comparar mÃ©tricas pre/post deploy
    pre_deploy = get_metrics_before_date(deploy_date)
    post_deploy = get_metrics_after_date(deploy_date)
    
    print("ðŸ“Š COMPARACIÃ“N PRE/POST DEPLOY:")
    print(f"Rating promedio: {pre_deploy['avg']} â†’ {post_deploy['avg']}")
    print(f"Issues crÃ­ticos: {pre_deploy['critical']} â†’ {post_deploy['critical']}")
    
    if post_deploy['avg'] > pre_deploy['avg']:
        print("âœ… Mejora detectada")
    else:
        print("âš ï¸ Revisar: no hay mejora aparente")
```

---

### **ðŸ“Š MÃ©tricas de Ã‰xito**

#### **KPIs por Fix**
```python
SUCCESS_METRICS = {
    "InformaciÃ³n incorrecta": {
        "target": "0% feedback 'Incorrecta'",
        "measure": "category == 'Incorrecta'"
    },
    
    "No encuentra productos": {
        "target": "Reducir 50% casos",
        "measure": "'no encuentra' in feedback_text"
    },
    
    "Tono inadecuado": {
        "target": "Rating promedio > 4.0",
        "measure": "avg(rating) where category == 'Tono inadecuado'"
    },
    
    "Escala demasiado": {
        "target": "Solo escalar con rating â‰¤ 2", 
        "measure": "escalation_logs vs conversation_ratings"
    }
}
```

---

### **ðŸ”„ Ciclo Continuo**

#### **Cada 2 Semanas: Review General**
1. **Trend analysis** - Â¿Mejoran los ratings?
2. **New patterns** - Â¿Aparecen nuevos problemas?
3. **Success validation** - Â¿Los fixes funcionaron?
4. **Next priorities** - Â¿QuÃ© atacar prÃ³ximamente?

#### **Monthly: Strategic Review**
1. **Overall bot performance** - Comparar con objetivos
2. **Client satisfaction** - Feedback del cliente final  
3. **Feature gaps** - Â¿QuÃ© funcionalidades faltan?
4. **Automation opportunities** - Â¿QuÃ© se puede automatizar?

---

## ðŸŽ¯ **Quick Reference: Problema â†’ SoluciÃ³n**

| Feedback | Archivo | AcciÃ³n TÃ­pica |
|----------|---------|---------------|
| "Info incorrecta" | `Entrenamiento/*.txt` | Actualizar datos base |
| "No encuentra X" | `woocommerce_mcp_tools.py` | Mejorar bÃºsqueda |
| "Muy agresivo" | `royal_agent_contextual.py` | Suavizar prompt |
| "Escala mucho" | `contextual_tools.py` | Subir thresholds |
| "Confuso" | `contextual_tools.py` | Activar mÃ¡s HITL |
| "Lento" | `*.py` (general) | Optimizar timeouts |

---

**ðŸ’¡ TIP:** Documenta cada fix en el commit message para trazabilidad:
```bash
git commit -m "Fix: Reduce false escalations for normal questions

- Increase frustration threshold from 1 to 2 indicators
- Remove 'confundido' from escalation triggers  
- Based on feedback: 'Escala por preguntas normales' (5 cases, avg rating 2.2)"
``` 