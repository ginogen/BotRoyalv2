#!/usr/bin/env python3
"""
ü§ñ SERVIDOR H√çBRIDO - ROYAL BOT
Combina la estabilidad del debug_server con el procesamiento de IA
"""

import os
import json
import asyncio
import logging
from datetime import datetime
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
import httpx

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Royal Bot Hybrid", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variables de entorno
EVOLUTION_API_URL = os.getenv("EVOLUTION_API_URL")
EVOLUTION_API_TOKEN = os.getenv("EVOLUTION_API_TOKEN") 
INSTANCE_NAME = os.getenv("INSTANCE_NAME", "F1_Retencion")

# Cliente HTTP global
http_client = None

@app.on_event("startup")
async def startup_event():
    global http_client
    http_client = httpx.AsyncClient(timeout=30.0)
    logger.info("üöÄ Servidor h√≠brido iniciado")

@app.on_event("shutdown") 
async def shutdown_event():
    global http_client
    if http_client:
        await http_client.aclose()

async def process_message_with_ai(user_id: str, message: str) -> str:
    """Procesa mensaje con IA - versi√≥n simplificada"""
    try:
        # Importar solo cuando se necesite para evitar errores de startup
        from royal_agents import run_contextual_conversation_sync
        
        logger.info(f"ü§ñ Procesando con IA: {user_id}")
        
        # Ejecutar en thread pool para no bloquear
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, 
            run_contextual_conversation_sync,
            user_id, 
            message
        )
        
        logger.info(f"‚úÖ IA respondi√≥ para {user_id}")
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Error procesando con IA: {e}")
        return "Disculp√°, tengo un problema t√©cnico. Un agente te va a contactar pronto."

async def send_whatsapp_response(phone: str, message: str) -> bool:
    """Env√≠a respuesta por WhatsApp"""
    try:
        if not all([EVOLUTION_API_URL, EVOLUTION_API_TOKEN, http_client]):
            logger.warning("Evolution API no configurada")
            return False
            
        headers = {
            "apikey": EVOLUTION_API_TOKEN,
            "Content-Type": "application/json"
        }
        
        payload = {
            "number": phone,
            "textMessage": {"text": message}
        }
        
        response = await http_client.post(
            f"{EVOLUTION_API_URL}/message/sendText/{INSTANCE_NAME}",
            headers=headers,
            json=payload
        )
        
        if response.status_code == 200:
            logger.info(f"üì§ Respuesta enviada a {phone}")
            return True
        else:
            logger.error(f"‚ùå Error Evolution API: {response.status_code}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error enviando respuesta: {e}")
        return False

@app.get("/")
async def root():
    return {
        "service": "Royal Bot Hybrid Server",
        "status": "working", 
        "message": "‚úÖ Servidor funcionando con IA",
        "version": "1.0.0",
        "features": [
            "‚úÖ Recepci√≥n de webhooks",
            "‚úÖ Procesamiento con IA", 
            "‚úÖ Respuestas autom√°ticas",
            "‚úÖ Healthcheck estable"
        ],
        "environment_vars": {
            "PORT": os.getenv("PORT", "not_set"),
            "OPENAI_API_KEY": "‚úÖ Set" if os.getenv("OPENAI_API_KEY") else "‚ùå Missing",
            "EVOLUTION_API_URL": "‚úÖ Set" if os.getenv("EVOLUTION_API_URL") else "‚ùå Missing",
            "EVOLUTION_API_TOKEN": "‚úÖ Set" if os.getenv("EVOLUTION_API_TOKEN") else "‚ùå Missing",
            "INSTANCE_NAME": os.getenv("INSTANCE_NAME", "not_set"),
        }
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "server": "hybrid_server",
        "message": "Servidor h√≠brido funcionando",
        "timestamp": datetime.now().isoformat()
    }

@app.post("/webhook/evolution")
async def evolution_webhook(request: Request):
    """Webhook para recibir mensajes de Evolution API con procesamiento IA"""
    try:
        data = await request.json()
        
        # Log del webhook recibido
        print(f"üì® Webhook Evolution recibido: {json.dumps(data, indent=2)}")
        
        # Extraer informaci√≥n b√°sica
        message_data_raw = data.get("data", {})
        message_content = message_data_raw.get("message", {}).get("conversation", "").strip()
        from_number = message_data_raw.get("key", {}).get("remoteJid", "").replace("@s.whatsapp.net", "")
        
        print(f"üì± Mensaje de {from_number}: {message_content}")
        
        # Si hay mensaje y n√∫mero, procesarlo con IA
        if message_content and from_number:
            # Procesar en background para no bloquear el webhook
            asyncio.create_task(process_and_respond(from_number, message_content))
            
            return {
                "status": "received",
                "message": "Mensaje recibido y procesando con IA",
                "from": from_number,
                "content": message_content[:50] + "..." if len(message_content) > 50 else message_content
            }
        else:
            return {
                "status": "received",
                "message": "Webhook recibido pero sin mensaje v√°lido"
            }
        
    except Exception as e:
        logger.error(f"‚ùå Error en webhook Evolution: {e}")
        return {
            "status": "error",
            "message": f"Error procesando webhook: {str(e)}"
        }

async def process_and_respond(phone: str, message: str):
    """Procesa mensaje y env√≠a respuesta - ejecuta en background"""
    try:
        user_id = f"whatsapp_{phone}"
        
        # Procesar con IA
        ai_response = await process_message_with_ai(user_id, message)
        
        # Enviar respuesta
        await send_whatsapp_response(phone, ai_response)
        
    except Exception as e:
        logger.error(f"‚ùå Error en proceso completo para {phone}: {e}")

@app.post("/test/message")
async def test_message(request: Request):
    """Endpoint para probar el procesamiento de IA"""
    try:
        data = await request.json()
        message = data.get("message", "Hola")
        user_id = data.get("user_id", "test_user")
        
        response = await process_message_with_ai(user_id, message)
        
        return {
            "status": "success",
            "input": message,
            "output": response,
            "user_id": user_id
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error en test: {e}")
        return {
            "status": "error",
            "message": str(e)
        }

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))
    logger.info(f"üöÄ Iniciando servidor h√≠brido en puerto {port}")
    uvicorn.run("hybrid_server:app", host="0.0.0.0", port=port, log_level="info")
